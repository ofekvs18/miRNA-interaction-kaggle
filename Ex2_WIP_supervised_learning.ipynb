{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UxQWDr56rKNe"
      },
      "source": [
        "# Names and IDs\n",
        " 1.\n",
        " 2."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E3Ay-R2L8veN"
      },
      "source": [
        "---\n",
        "# Section 1\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cGW6xKPJraNC"
      },
      "source": [
        "# I. Naive Bayes (40 pts)\n",
        "\n",
        "In this part we will test digits classification on the MNIST dataset, using Bernoulli Naive Bayes (a generative model), in contrast to the Multivariate Logistic Regression (a discriminative model) we saw.\n",
        "\n",
        "The MNIST dataset contains 28x28 grayscale images of handwritten digits between 0 and 9 (10 classes). For mathmatical analysis clarity, and for matching expected API, each image faltten to create a 1D array with 784 elements."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EPTebxKjFgQw"
      },
      "source": [
        "### Loading the MNIST dataset\n",
        "Load the MNIST data set. The digits dataset is one of datasets scikit-learn comes with that do not require the downloading of any file from some external website. Use\n",
        "\n",
        "```\n",
        "from keras.datasets import mnist\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "```\n",
        "\n",
        "To fetch the original data. Each image is a 28 by 28 pixels in grayscale range [0,255] and the corresponding label is an integer $y\\in [0,9]$. Each image should be transformed into a 1D integer array $x\\in [0,255]^{784}$.\n",
        "\n",
        "```\n",
        "x_train = x_train.reshape(x_train.shape[0], 784)\n",
        "x_test = x_test.reshape(x_test.shape[0], 784)\n",
        "```\n",
        "\n",
        "Divide your data into train and test sets in a 80-20 ration split. And plot a single sample of each digit as the original image, so you get a feeling how the data looks like."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VOTwTtZUFgQw"
      },
      "outputs": [],
      "source": [
        "# Implement here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "02M_QCRQFgQx"
      },
      "source": [
        "### Bernoulli Naive Bayes\n",
        "If we know how the digits are generated, then we know how to classify them (simply choose the digit class which will maximize the posterior probability) --- but which model should we use for describing the digits generation?\n",
        "\n",
        "In this part we will try a very simplified model of digits creation (which is obviously not the same as the \"real\" model), using a Naive Bayes over an underlying Bernoulli distribution --- that is, we will assume that given a digit class, the pixels of the images are the result of independent coin flips, each with its own \"head\" probability.\n",
        "\n",
        "Note that since we assume each pixl is either 0 (black) or 1 (white), we will need to adjust (preprocess) our data accrodingly (see below).\n",
        "\n",
        "So, the model is stated as follows:\n",
        "$$\n",
        "\\begin{align}\n",
        "\\text{Domain} && x \\in \\{0,1\\}^{784} \\\\\n",
        "\\text{Prior} && \\pi_j = \\Pr(y=j) \\\\\n",
        "\\text{Likelihood} && P_j(x) = \\Pr(x | y=j) \\\\\n",
        "\\end{align}\n",
        "$$\n",
        "\n",
        "Where for each $i\\in 0\\ldots 784$ it holds that the probability of a pixel $i$ to be on given that the digit is $j$ is:\n",
        "$$\n",
        "P_{ji}(x_i) = \\Pr(x_i | y=j) =\n",
        "\\begin{cases}\n",
        "p_{ji} & \\text{if } x_i=1 \\\\\n",
        "1-p_{ji} & \\text{if } x_i=0 \\\\\n",
        "\\end{cases}\n",
        "$$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qofRJulpFgQx"
      },
      "source": [
        "#### Question 1\n",
        "Research the differences between the three types of Naive Bayes classifiers: Bernoulli NB, Multinomial NB, and Gaussian NB.\n",
        "Describe in your own words what makes each type unique and specify the kind of tasks for which you would prefer each one."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a3o3lLHwFgQy"
      },
      "source": [
        "#### Answer 1\n",
        "Put you answer here..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s-SPK9Y1FgQy"
      },
      "source": [
        "#### Question 2\n",
        "Train a Naive Bayes classifier using the training data and apply predictions on the test data. Use the [sklearn.naive_bayes.BernoulliNB](http://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.BernoulliNB.html) implementation (see the [source code for sklearn.naive_bayes](https://github.com/scikit-learn/scikit-learn/blob/master/sklearn/naive_bayes.py) for details).\n",
        "\n",
        "Remember we need to preprocess the data in this case such that each pixel would become either black (0) or white (1). For this purpose, use the `binarize` parameter of the `BernoulliNB` function. Set this value to $0$ (this is the default), which in this case would mean every pixel with non-zero value will be set to 1.\n",
        "\n",
        "1. Plot the confusion matrix of your classifier, as claculated on the test data (it is recommended to use [sklearn.metrics.confusion_matrix](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html)). Calculate the total accuracy (fraction of correctly classified images), and summarize the results in your own words.\n",
        "\n",
        "    A **confusion matrix** for a multi-class classifier is a table that summarizes the performance of the model by comparing the predicted class labels to the true class labels: Each row represents the actual class, and each column represents the predicted class. The diagonal elements indicate the number of correct predictions for each class. Off-diagonal elements show misclassifications (e.g., how many times one class was predicted as another).\n",
        "\n",
        "\n",
        "2. Plot the mean image of each class (estimated $\\hat{p}_{ji}$) and generate one sample of each class (remember, you can do this since this is a generative model). You will need to access the `feature_log_prob_` attribute of the trained model.\n",
        "\n",
        "3. Think of a way you can find the optimal threshold of the binarization part. **There is no need to actually perform this task --- just describe what you would have done.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bv0-LIIuFgQy"
      },
      "source": [
        "#### Answer 2\n",
        "Put you answer here..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "szTYDcHqFgQy"
      },
      "outputs": [],
      "source": [
        "# code goes here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lcJ7eHwT_MpO"
      },
      "source": [
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0NbhT1k_BT0P"
      },
      "source": [
        "---\n",
        "# Section 2 - Kaggle competition\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TSg53ugU5d44"
      },
      "source": [
        "# miRNA animals interaction prediction (60 pts)\n",
        "In this section, you will explain the tools and methods you used in the competition. Fifty points will be given according to the explanations of the section and up to ten points according to your relative position in the competition. Participate in the following contest and answer the following questions:\n",
        "https://www.kaggle.com/t/ae45745d840546ffa91755d7a06af0d7\n",
        "\n",
        "In this section you are allow to use only Decision Tree as your ML model.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# imports\n",
        "from google.colab import drive\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import cross_val_score, train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder,OneHotEncoder\n",
        "from sklearn.impute import SimpleImputer, KNNImputer\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, balanced_accuracy_score,\n",
        "    precision_score, recall_score, f1_score,\n",
        "    classification_report, confusion_matrix\n",
        ")\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n"
      ],
      "metadata": {
        "id": "eXWogjM48yrr"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# data import\n",
        "drive.mount('/content/drive')\n",
        "x_train = pd.read_csv(\"/content/drive/Shareddrives/ML/x_train.csv\", index_col=\"id\")\n",
        "y_train = pd.read_csv(\"/content/drive/Shareddrives/ML/y_train.csv\", index_col=\"id\")\n",
        "\n",
        "x_test = pd.read_csv(\"/content/drive/Shareddrives/ML/x_test.csv\", index_col=\"id\")"
      ],
      "metadata": {
        "id": "HGLKWBBR80E3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3757824d-3d75-4d0e-f3b7-db0270be02c1"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lKlBIDpz5d45"
      },
      "source": [
        "### EDA - Exploratory Data Analysis (10 pts):\n",
        "Use any visual tools to present and explain the data. Your answer must include statistics, images, and conclusions.\n",
        "\n",
        "***Write your code below***\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "JD9_w6lT5d45",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab8db385-3bba-4149-f50b-8b2fff54d85f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ],
      "source": [
        "# Implement here\n",
        "x_train['HotPairingMRNA_he_P1_L1'].nunique(dropna=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FVD23l5Y5d45"
      },
      "outputs": [],
      "source": [
        "# Explain here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SAa8Tc_n5d46"
      },
      "source": [
        "### Preprocessing (10 pts):\n",
        "Describe in detail what did you do in the preprocessing phase and why you did it.\n",
        "\n",
        "***Write your code below***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "jmAKt6O95d46",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78baa242-9eb5-49a3-8832-db5660570307"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best parameters: {'classifier__max_depth': 10, 'classifier__min_samples_leaf': 10}\n",
            "Best cross-validated F1 score: 0.6080550098231827\n"
          ]
        }
      ],
      "source": [
        "# Implement here\n",
        "labeled_mask = y_train['label'].notnull()\n",
        "x_labeled = x_train.loc[labeled_mask]\n",
        "y_labeled = y_train.loc[labeled_mask]\n",
        "x_not_labeled = x_train.loc[~labeled_mask]\n",
        "\n",
        "x_trainval, x_traintest, y_trainval, y_traintest = train_test_split(\n",
        "    x_labeled, y_labeled,\n",
        "    test_size=0.2,\n",
        "    stratify=y_labeled,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "\n",
        "class DropZeroStd(BaseEstimator, TransformerMixin):\n",
        "    def fit(self, X, y=None):\n",
        "        # get only numerical columns\n",
        "        X = X.select_dtypes(include=['int64', 'float64'])\n",
        "        stds = X.std(axis=0, skipna=True)\n",
        "        self.columns_to_keep_ = stds[stds > 0].index.tolist()\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        return X[self.columns_to_keep_]\n",
        "\n",
        "def build_preprocessor(X):\n",
        "\n",
        "    # Drop zero-std columns (done as a step in the full pipeline)\n",
        "    dropzerostd = DropZeroStd()\n",
        "    X_clean = dropzerostd.fit_transform(X.copy())\n",
        "\n",
        "    # Detect boolean numeric columns\n",
        "    bool_cols = [\n",
        "        col for col in X_clean.select_dtypes(include=['int64', 'float64']).columns\n",
        "        if set(X_clean[col].dropna().unique()).issubset({0, 1})\n",
        "    ]\n",
        "\n",
        "    # All object/category/bool columns\n",
        "    cat_cols = (\n",
        "        X_clean.select_dtypes(include=['object', 'category', 'bool']).columns.tolist()\n",
        "        + bool_cols\n",
        "    )\n",
        "    cat_cols = list(set(cat_cols))  # remove duplicates\n",
        "\n",
        "    # Final numeric columns = numeric - bool\n",
        "    num_cols = [\n",
        "        col for col in X_clean.select_dtypes(include=['int64', 'float64']).columns\n",
        "        if col not in cat_cols\n",
        "    ]\n",
        "\n",
        "    # Pipelines\n",
        "    num_pipeline = Pipeline([\n",
        "        ('imputer', SimpleImputer(strategy='mean')),\n",
        "        ('scaler', StandardScaler())\n",
        "    ])\n",
        "\n",
        "    cat_pipeline = Pipeline([\n",
        "        ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "        ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
        "    ])\n",
        "\n",
        "    # Column transformer\n",
        "    preprocessor = Pipeline([\n",
        "        ('drop_const', dropzerostd),\n",
        "        ('column_processing', ColumnTransformer([\n",
        "            ('num', num_pipeline, num_cols),\n",
        "            ('cat', cat_pipeline, cat_cols)\n",
        "        ]))\n",
        "    ])\n",
        "\n",
        "    return preprocessor\n",
        "\n",
        "# 1. Build preprocessing + model pipeline\n",
        "model_pipeline = Pipeline([\n",
        "    ('preprocessor', build_preprocessor(x_trainval)),\n",
        "    ('classifier', DecisionTreeClassifier(random_state=42))\n",
        "])\n",
        "\n",
        "# 2. Define parameter grid for the classifier\n",
        "param_grid = {\n",
        "    'classifier__max_depth': [3, 5, 10, None],\n",
        "    'classifier__min_samples_leaf': [1, 5, 10]\n",
        "}\n",
        "\n",
        "# 3. Setup grid search with CV\n",
        "grid = GridSearchCV(\n",
        "    model_pipeline,\n",
        "    param_grid=param_grid,\n",
        "    cv=5,  # Number of folds\n",
        "    scoring='accuracy',  # or accuracy, recall, etc.\n",
        "    n_jobs=-1  # parallelism if supported\n",
        ")\n",
        "\n",
        "# 4. Run grid search on your training data\n",
        "grid.fit(x_trainval, y_trainval)\n",
        "\n",
        "# 5. Get best model and score\n",
        "print(\"Best parameters:\", grid.best_params_)\n",
        "print(\"Best cross-validated F1 score:\", grid.best_score_)\n",
        "\n",
        "# 6. Use grid.best_estimator_ to make predictions on x_\n",
        "y_pred = grid.score(x_traintest, y_traintest)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "64Ffk22j5d46"
      },
      "outputs": [],
      "source": [
        "# Explain here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4UQuCnrV5d47"
      },
      "source": [
        "### Model training (15 pts):\n",
        "Train your Decision Tree model.\n",
        "Explain in detail what model you used to achieve your highest score, what the hyper-parameters were, and why did you choose both the model and these parameters.\n",
        "Attach at least two learning plot and explain them.\n",
        "\n",
        "***Write your code below***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "es7hYpJp5d47"
      },
      "outputs": [],
      "source": [
        "# Implement here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CX54NFal5d47"
      },
      "outputs": [],
      "source": [
        "# Explain here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6c5p9F9b5d47"
      },
      "source": [
        "### Model evaluation (15 pts):\n",
        "Eevaluate your ML model using different evaluation metrics.\n",
        "For every evaluation metric mention below add your model score and answer the following questions:\n",
        "\n",
        "What does this evaluation metric mean? is it relevant to this prediction task?\n",
        "Do you think the score you got is good for this task?\n",
        "\n",
        "\n",
        "***Write your code below***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "Zze4--G55d48"
      },
      "outputs": [],
      "source": [
        "# Implement here\n",
        "\n",
        "best_model = grid.best_estimator_\n",
        "y_pred = best_model.predict(x_test)\n",
        "# If 'id' is a column in X_test:\n",
        "submission = pd.DataFrame({\n",
        "    'id': x_test.index,       # or X_test.index if it's the index\n",
        "    'label': y_pred\n",
        "})\n",
        "\n",
        "submission.to_csv('submission.csv', index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tYg8UWwh5d48"
      },
      "outputs": [],
      "source": [
        "# List of evaluation metrics\n",
        "# Accuracy -\n",
        "# Balanced Accuracy -\n",
        "# Micro Precision -\n",
        "# Micro Recall -\n",
        "# Micro F1-score -\n",
        "# Macro Precision -\n",
        "# Macro Recall -\n",
        "# Macro F1-score -\n",
        "# Weighted Precision -\n",
        "# Weighted Recall -\n",
        "# Weighted F1-score -"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZHhXTVpq5d48"
      },
      "source": [
        "### Explainability (10 pts):\n",
        "Explain the results of your model using SHAP and attach relevant outputs. Explain at least three conclusions following the SHAP outputs.\n",
        "\n",
        "**Note:**\n",
        "Use the animal names in your conclusions and not the label numbers.\n",
        "\n",
        "***Write your code below***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2E8mMFye5d49"
      },
      "outputs": [],
      "source": [
        "# Implement here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SlhVqNcV5d49"
      },
      "outputs": [],
      "source": [
        "# Explain here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4_9pNNXQ5d49"
      },
      "source": [
        "### Competition rank (5 pts - bonus):\n",
        "The competition will be open until 10.6.25 at 23:59. The results of the competition will be published about 12 hours later under the private tab on the leaderboard.\n",
        "\n",
        "The scoring of this section is relative to the location (between 0-5 pts).\n",
        "\n",
        "Indicate here your team name in the competition and **attach an additinal notebook\\python code** with which we can reproduce the rank you received.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tIfyB8Ed5d49"
      },
      "outputs": [],
      "source": [
        "# My team name was:"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "UxQWDr56rKNe",
        "0NbhT1k_BT0P"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}